{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "495b776a",
   "metadata": {},
   "source": [
    "# Module import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69742659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import lightgbm \n",
    "from lightgbm import LGBMClassifier\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685672bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze > requirements.txt\n",
    "\n",
    "# python==3.7.9\n",
    "# jupyter==1.0.0\n",
    "# lightgbm==3.3.2\n",
    "# numpy==1.21.6\n",
    "# optuna==2.10.1\n",
    "# pandas==1.3.5\n",
    "# scikit-learn==1.0.2\n",
    "# sklearn==0.0\n",
    "# tensorboard==2.9.1\n",
    "# torch==1.12.0\n",
    "# tqdm==4.64.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fd7deb",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5611ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./dacon/train.csv')\n",
    "valid = pd.read_csv('./dacon/val.csv')\n",
    "test = pd.read_csv('./dacon/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8912fc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = train.drop(['ID'] , axis = 1) \n",
    "testset = test.drop(['ID'] , axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee782abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0010540369615627855\n"
     ]
    }
   ],
   "source": [
    "fraud_ratio = valid['Class'].values.sum() / len(valid)\n",
    "print(fraud_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f4127c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EllipticEnvelope(contamination=0.0010540369615627855, random_state=42,\n",
       "                 support_fraction=0.994)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fraud ratio (Valid와 동일하게)\n",
    "# 하지만 contamination을 valid와 동일하게 하든 몇 배로 해서 모델을 만들든\n",
    "# 나중에 본인이 score를 내림차순하여 원하는 개수만큼 이상치 개수를 정할 수 있는 것을 확인했기에 크게 의미는 없다고 생각함 \n",
    "# 정리하자면, \n",
    "# 1) contamination을 몇으로 놓든 간에 정의한 함수 get_pred_label을 이용해 outlier label 개수를 조절 가능 \n",
    "# 2) 극단적으로 contamination을 0.1로 두든 1로 두든 get_pred_label 함수에서 k를 똑같이주어 사용하면 결과는 똑같음 \n",
    "\n",
    "model = EllipticEnvelope(support_fraction = 0.994, contamination = fraud_ratio, random_state = 42) \n",
    "model.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e488bc6c",
   "metadata": {},
   "source": [
    "# Ensemble을 위한 test prediction value 1 획득"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d410cd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_label(model, x, k):\n",
    "  prob = model.score_samples(x)\n",
    "  prob = torch.tensor(prob, dtype = torch.float)\n",
    "  topk_indices = torch.topk(prob, k = k, largest = False).indices\n",
    "\n",
    "  pred = torch.zeros(len(x), dtype = torch.long)\n",
    "  pred[topk_indices] = 1\n",
    "  return pred , prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62691ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 313개로 fraud label 개수를 정한 이유는, \n",
    "# https://dacon.io/competitions/official/235930/codeshare/5694?page=1&dtype=recent 게시글 작성자 \n",
    "# Akynella님이 공유해주신 내용을 토대로 318개 근처의 값을 사용, 이후 public score 참고하여 적절하게 조정\n",
    "\n",
    "# 이 과정에서 학습의 일관성이나 논리에 조금 어긋난다고 느낀 것은\n",
    "# testset도 fraud label의 비율을 앞 두개의 dataset과 동일하게 두어야 논리나 일관성이 있지 않았나하는 생각이 듦\n",
    "# 즉, test에도 train이나 valid와 동일하게 fraud label 비율을 가져갔으면 약 150개 정도의 fraud label을 주어야 일관성이 있는거라\n",
    "# 생각함. 하지만 그렇게 두면 public score가 좋지 않고, 실제로 코드 공유 게시판을 참조한 결과 \n",
    "# testset에 더 많은 비율의 fraud label이 존재함을 인지 및 예상\n",
    "\n",
    "test_pred, _ = get_pred_label(model, testset, 313)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b701166",
   "metadata": {},
   "outputs": [],
   "source": [
    "envelope_pred = np.array(test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b16129a",
   "metadata": {},
   "source": [
    "# 분류 모델링을 위한 trainset label 임의 획득"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "255b4a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid와 동일한 비율 118~120개 사이의 fraud label을 가질 거라 가정하여 label 획득\n",
    "# trainset의 label을 임의로 준 이유는 지도학습의 결과를 함께 앙상블하기 위함\n",
    "# 물론, 일정 부분 잘못된 label을 부여하고 학습을 하는 것이 논리에 어긋나지만 \n",
    "# 하나라도 사기 거래를 잘 찾아내는 것에 집중하기 위해 잘못된 label을 주고 모델 학습\n",
    "\n",
    "train_pred, _ = get_pred_label(model, trainset, 118)\n",
    "Y = np.array(train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c6262c",
   "metadata": {},
   "source": [
    "# 모델 최적화 (optuna module 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9fb4584",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#skf = StratifiedKFold(n_splits = 5 , random_state = 42 , shuffle = True)\n",
    "\n",
    "score = []\n",
    "def lgb_optimization(trial):\n",
    "    score = []\n",
    "    skf = StratifiedKFold(n_splits = 5 , random_state = 42 , shuffle = True)\n",
    "    for train_fold, test_fold in tqdm(skf.split(trainset, Y), desc = 'k_fold'):\n",
    "        X_train, X_test, y_train, y_test = trainset.iloc[train_fold], trainset.iloc[test_fold], Y[train_fold], Y[test_fold] \n",
    "        \n",
    "        params = {            \n",
    "            \"boosting_type\" : trial.suggest_categorical('boosting_type',['dart','gbdt']),\n",
    "            \"learning_rate\": trial.suggest_uniform('learning_rate', 0.2, 0.99),\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 300, step=10),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 1, 15),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "            \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-4, 1),\n",
    "            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-4, 1),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.4, 1.0),\n",
    "            \"subsample_freq\": trial.suggest_int(\"subsample_freq\", 1, 30),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.1, 1.0),\n",
    "            \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 50),\n",
    "            \"max_bin\": trial.suggest_int(\"max_bin\", 50, 100),\n",
    "            \"verbosity\": -1,\n",
    "            \"random_state\": trial.suggest_int(\"random_state\", 1, 10000)\n",
    "        }\n",
    "        model_lgb = LGBMClassifier(**params)\n",
    "        model_lgb.fit(X_train, y_train)\n",
    "        lgb_cv_pred = model_lgb.predict(X_test)\n",
    "        \n",
    "        score_cv = f1_score(Y[test_fold] , lgb_cv_pred , average = 'macro')\n",
    "        \n",
    "        score.append(score_cv)\n",
    "    print(score)\n",
    "    return np.mean(score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7db8b16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-07 21:21:46,786]\u001b[0m A new study created in memory with name: lgb_parameter_opt\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a463d4a80ccf44fe90b12ed0b1c7ae40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k_fold: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-07 21:21:49,064]\u001b[0m Trial 0 finished with value: 0.915937548811956 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.3442808156351922, 'n_estimators': 150, 'max_depth': 5, 'num_leaves': 255, 'reg_alpha': 0.6650049125182595, 'reg_lambda': 0.07149894673714025, 'subsample': 0.8773599627692386, 'subsample_freq': 28, 'colsample_bytree': 0.4058256778727659, 'min_child_samples': 5, 'max_bin': 95, 'random_state': 8622}. Best is trial 0 with value: 0.915937548811956.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9090029854086653, 0.8694333260697533, 0.8999010793343738, 0.9666336931114579, 0.934716660135529]\n",
      "Best macro-F1: 0.915937548811956\n"
     ]
    }
   ],
   "source": [
    "# 1-fold , 2-fold ... 20-fold 분할 및 성능 평가와\n",
    "# Best Hyper-parameter를 순차적으로 고정+탐색 , 고정+고정+탐색.. 하는 방식으로 \n",
    "# 가장 train label을 안정적으로 찾는 parameter를 획득\n",
    "# 해당 code엔 편의상 5 fold로 명시\n",
    "\n",
    "sampler = TPESampler()\n",
    "optim = optuna.create_study(\n",
    "    study_name=\"lgb_parameter_opt\",\n",
    "    direction=\"maximize\",\n",
    "    sampler=sampler,\n",
    ")\n",
    "#optim.optimize(lgb_optimization, n_trials=1)\n",
    "optim.optimize(lgb_optimization, n_trials=99999)\n",
    "print(\"Best macro-F1:\", optim.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de2e7702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 획득한 Lightgbm의 best parameter \n",
    "\n",
    "params = {'boosting_type': 'gbdt', 'learning_rate': 0.27931562561080087,\n",
    " 'n_estimators': 180, 'max_depth': 2, 'num_leaves': 79, 'reg_alpha': 0.7804924821497133,\n",
    " 'reg_lambda': 0.6483886637315736, 'subsample': 0.5046737928606037, 'subsample_freq': 27,\n",
    " 'colsample_bytree': 0.2884662481524903, 'min_child_samples': 39, 'max_bin': 69}\n",
    "#random_state = 3294"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07eb7ffd",
   "metadata": {},
   "source": [
    "# Ensemble을 위한 test prediction value 2 획득"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac5b836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = LGBMClassifier(**params , random_state = 3294)\n",
    "model2.fit(trainset, Y)\n",
    "lgb_pred = model2.predict(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a77cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble 시,  AorB : true 조건을 사용한 이유는 \n",
    "# 두 예측 시스템에서 최소 1번이라도 fraud로 예측된 example은 fraud로 의사 결정을 내리기 위함\n",
    "# 이유 :: 사기 거래 탐지는 보수적인 의사 결정을 해야 옳다고 생각했기 때문에.\n",
    "\n",
    "sub = pd.read_csv('./dacon/sample_submission.csv')\n",
    "sub['Class'] = envelope_pred|lgb_pred # Ensemble \n",
    "sub.to_csv('./dacon/final_submission.csv' , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64238992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142503 142503\n"
     ]
    }
   ],
   "source": [
    "# 대회 중 최종 제출 파일(stateopt.csv)과 동일한지 checking \n",
    "\n",
    "final_sub = pd.read_csv('./dacon/stateopt.csv')\n",
    "\n",
    "print(sum(sub['Class'].values == final_sub['Class'].values),\n",
    "      len(testset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
